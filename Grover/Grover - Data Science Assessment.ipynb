{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "93cc0e67",
   "metadata": {},
   "source": [
    "#### PROJECT : GROVER - Data Science Assessment $\\;\\;\\;\\;\\;\\;\\;\\;\\;\\;\\;\\;\\;\\;\\;\\;$  Author: Adegboyega Adesanya $\\;\\;\\;\\;\\;\\;\\;\\;\\;\\;\\;\\;\\;\\;\\;\\;\\;\\;\\;\\;\\;\\;\\;\\;\\;$  Date: Feb 28, 2022"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "09fe5f97",
   "metadata": {},
   "source": [
    "#### Objective:\n",
    "Build a Machine Learning Model that correctly classifies label \" y \" maximizing performance on validation data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0184bd90",
   "metadata": {},
   "source": [
    "#### Steps/Approach (CRISP-DM Methodology):\n",
    "- **Business Understanding** - Understand the business pain point from the objectives we are looking to achieve.\n",
    "- **Data Gathering** - Gather relevant data to solve business problem (the provided data)\n",
    "- **Data understanding** - A quick run through the data to understand each field and what it means.\n",
    "- **Data Preparation:**\n",
    "    - *Exploratory Data Analysis (EDA)*: Here the data is assessed and visualized to better understand it\n",
    "    - *Data Cleaning/ Preprocessing*: Missing values are handled here, unwanted data are dropped or modified to suit our purpose\n",
    "    - *Data Preparation for modelling*: Here we balance the dataset if possible, tokenize it, normalize/standardize the data\n",
    "- **Modelling** - Using different machine learning algorithms, we train several models, tune its parameters and select one which best solve the business problem\n",
    "- **Evaluation** - This is based on the selected model; we evaluate it with the holdout/ test dataset. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "762d6f12",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import necessary data manipulation libraries\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# Import the neccessary machine learning libraries\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier, AdaBoostClassifier\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.linear_model import LogisticRegression \n",
    "from sklearn.model_selection import cross_val_score,RandomizedSearchCV\n",
    "from sklearn.metrics import accuracy_score, classification_report, confusion_matrix\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.feature_selection import f_classif\n",
    "\n",
    "# import necessary statistical library\n",
    "from scipy.stats import chi2_contingency\n",
    "\n",
    "# import the SMOTE library from imblearn for the purpose of balancing the dataset\n",
    "from imblearn.over_sampling import SMOTE\n",
    "\n",
    "# import necessary data visualization libraries\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "sns.set()\n",
    "\n",
    "# Necessary Settings\n",
    "pd.set_option('display.max_columns', None)\n",
    "pd.set_option('display.max_rows', None)\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e42aa7f5",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>x.0</th>\n",
       "      <th>x.1</th>\n",
       "      <th>x.2</th>\n",
       "      <th>x.3</th>\n",
       "      <th>x.4</th>\n",
       "      <th>x.5</th>\n",
       "      <th>x.6</th>\n",
       "      <th>x.7</th>\n",
       "      <th>x.8</th>\n",
       "      <th>x.9</th>\n",
       "      <th>x.10</th>\n",
       "      <th>x.11</th>\n",
       "      <th>x.12</th>\n",
       "      <th>x.13</th>\n",
       "      <th>x.14</th>\n",
       "      <th>x.20</th>\n",
       "      <th>x.17</th>\n",
       "      <th>x.18</th>\n",
       "      <th>x.19</th>\n",
       "      <th>x.16</th>\n",
       "      <th>y</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>b</td>\n",
       "      <td>30,83</td>\n",
       "      <td>f</td>\n",
       "      <td>u</td>\n",
       "      <td>g</td>\n",
       "      <td>w</td>\n",
       "      <td>v</td>\n",
       "      <td>1.25</td>\n",
       "      <td>t</td>\n",
       "      <td>t</td>\n",
       "      <td>t</td>\n",
       "      <td>f</td>\n",
       "      <td>g</td>\n",
       "      <td>202.0</td>\n",
       "      <td>f</td>\n",
       "      <td>t</td>\n",
       "      <td>116,94256980957068</td>\n",
       "      <td>0,5787085579422866</td>\n",
       "      <td>202000.0</td>\n",
       "      <td>f</td>\n",
       "      <td>good</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>a</td>\n",
       "      <td>58,67</td>\n",
       "      <td>4.46</td>\n",
       "      <td>u</td>\n",
       "      <td>g</td>\n",
       "      <td>q</td>\n",
       "      <td>h</td>\n",
       "      <td>3.04</td>\n",
       "      <td>t</td>\n",
       "      <td>t</td>\n",
       "      <td>6</td>\n",
       "      <td>f</td>\n",
       "      <td>g</td>\n",
       "      <td>43.0</td>\n",
       "      <td>560</td>\n",
       "      <td>t</td>\n",
       "      <td>225,60625307204938</td>\n",
       "      <td>25,409645364400404</td>\n",
       "      <td>43000.0</td>\n",
       "      <td>f</td>\n",
       "      <td>good</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>a</td>\n",
       "      <td>24,5</td>\n",
       "      <td>0.5</td>\n",
       "      <td>u</td>\n",
       "      <td>g</td>\n",
       "      <td>q</td>\n",
       "      <td>h</td>\n",
       "      <td>1.5</td>\n",
       "      <td>t</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>g</td>\n",
       "      <td>280.0</td>\n",
       "      <td>824</td>\n",
       "      <td>t</td>\n",
       "      <td>92,08407670672422</td>\n",
       "      <td>2,3173371593153314</td>\n",
       "      <td>280000.0</td>\n",
       "      <td>f</td>\n",
       "      <td>good</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>b</td>\n",
       "      <td>27,83</td>\n",
       "      <td>1.54</td>\n",
       "      <td>u</td>\n",
       "      <td>g</td>\n",
       "      <td>w</td>\n",
       "      <td>v</td>\n",
       "      <td>3.75</td>\n",
       "      <td>t</td>\n",
       "      <td>t</td>\n",
       "      <td>5</td>\n",
       "      <td>t</td>\n",
       "      <td>g</td>\n",
       "      <td>100.0</td>\n",
       "      <td>3</td>\n",
       "      <td>t</td>\n",
       "      <td>104,16291777029285</td>\n",
       "      <td>8,04533772976642</td>\n",
       "      <td>100000.0</td>\n",
       "      <td>f</td>\n",
       "      <td>good</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>b</td>\n",
       "      <td>20,17</td>\n",
       "      <td>5.625</td>\n",
       "      <td>u</td>\n",
       "      <td>g</td>\n",
       "      <td>w</td>\n",
       "      <td>v</td>\n",
       "      <td>1.71</td>\n",
       "      <td>t</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>s</td>\n",
       "      <td>120.0</td>\n",
       "      <td>f</td>\n",
       "      <td>t</td>\n",
       "      <td>77,8703024439662</td>\n",
       "      <td>31,111460957322073</td>\n",
       "      <td>120000.0</td>\n",
       "      <td>f</td>\n",
       "      <td>good</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  x.0    x.1    x.2 x.3 x.4 x.5 x.6   x.7 x.8 x.9 x.10 x.11 x.12   x.13 x.14  \\\n",
       "0   b  30,83      f   u   g   w   v  1.25   t   t    t    f    g  202.0    f   \n",
       "1   a  58,67   4.46   u   g   q   h  3.04   t   t    6    f    g   43.0  560   \n",
       "2   a   24,5    0.5   u   g   q   h   1.5   t   f    f    f    g  280.0  824   \n",
       "3   b  27,83   1.54   u   g   w   v  3.75   t   t    5    t    g  100.0    3   \n",
       "4   b  20,17  5.625   u   g   w   v  1.71   t   f    f    f    s  120.0    f   \n",
       "\n",
       "  x.20                x.17                x.18      x.19 x.16     y  \n",
       "0    t  116,94256980957068  0,5787085579422866  202000.0    f  good  \n",
       "1    t  225,60625307204938  25,409645364400404   43000.0    f  good  \n",
       "2    t   92,08407670672422  2,3173371593153314  280000.0    f  good  \n",
       "3    t  104,16291777029285    8,04533772976642  100000.0    f  good  \n",
       "4    t    77,8703024439662  31,111460957322073  120000.0    f  good  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## Read in the trainind dataset\n",
    "data = pd.read_csv('training_grover.csv',sep=';', index_col=0)\n",
    "data.head(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cfe0e798",
   "metadata": {},
   "source": [
    "### Data Understanding\n",
    "\n",
    "Here the data was read in and a quick snoop through the data was made to understand each feature in it. Understanding each feature entails we understand the data types in each feature and how they can be handled for our analysis."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "30e0bcb8",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2671, 21)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "### checking the dataset shape\n",
    "data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "8aa9cafa",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 2671 entries, 0 to 2670\n",
      "Data columns (total 21 columns):\n",
      " #   Column  Non-Null Count  Dtype \n",
      "---  ------  --------------  ----- \n",
      " 0   x.0     2671 non-null   object\n",
      " 1   x.1     2671 non-null   object\n",
      " 2   x.2     2671 non-null   object\n",
      " 3   x.3     2671 non-null   object\n",
      " 4   x.4     2671 non-null   object\n",
      " 5   x.5     2671 non-null   object\n",
      " 6   x.6     2671 non-null   object\n",
      " 7   x.7     2671 non-null   object\n",
      " 8   x.8     2671 non-null   object\n",
      " 9   x.9     2671 non-null   object\n",
      " 10  x.10    2671 non-null   object\n",
      " 11  x.11    2671 non-null   object\n",
      " 12  x.12    2671 non-null   object\n",
      " 13  x.13    2671 non-null   object\n",
      " 14  x.14    2671 non-null   object\n",
      " 15  x.20    2671 non-null   object\n",
      " 16  x.17    2671 non-null   object\n",
      " 17  x.18    2671 non-null   object\n",
      " 18  x.19    2671 non-null   object\n",
      " 19  x.16    2671 non-null   object\n",
      " 20  y       2671 non-null   object\n",
      "dtypes: object(21)\n",
      "memory usage: 459.1+ KB\n"
     ]
    }
   ],
   "source": [
    "# a quick overview of the general dataset\n",
    "data.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cc44cd05",
   "metadata": {},
   "source": [
    "#### Quick snoop into the data\n",
    "\n",
    "This helps in better understanding of the data and how preprocessing can be done "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "61289f3a",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "b    1833\n",
       "a     823\n",
       "?      15\n",
       "Name: x.0, dtype: int64"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data['x.0'].value_counts()  ## ?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "d6942208",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "23,25    47\n",
       "35,17    41\n",
       "39,92    37\n",
       "19,17    33\n",
       "24,5     28\n",
       "Name: x.1, dtype: int64"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## Numerical values with commas\n",
    "data['x.1'].value_counts().head() # , ?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "6389fa6b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "6.5     74\n",
       "f       73\n",
       "0.5     70\n",
       "5.0     69\n",
       "11.0    66\n",
       "Name: x.2, dtype: int64"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# feature with mixed data type string and numerics\n",
    "data['x.2'].value_counts().head()  ## f, t"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "db05075e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "u    2166\n",
       "y     464\n",
       "?      24\n",
       "l      17\n",
       "Name: x.3, dtype: int64"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data['x.3'].value_counts() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "3035608b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "g     2166\n",
       "p      464\n",
       "?       24\n",
       "gg      17\n",
       "Name: x.4, dtype: int64"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data['x.4'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "88ae3839",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "q     539\n",
       "c     422\n",
       "cc    290\n",
       "w     259\n",
       "x     198\n",
       "i     170\n",
       "aa    159\n",
       "m     149\n",
       "k     145\n",
       "e     114\n",
       "ff     85\n",
       "d      82\n",
       "?      25\n",
       "j      25\n",
       "r       9\n",
       "Name: x.5, dtype: int64"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data['x.5'].value_counts()  # ? "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "4837728a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "v     1415\n",
       "h      774\n",
       "bb     279\n",
       "ff      96\n",
       "z       44\n",
       "?       25\n",
       "j       13\n",
       "n       11\n",
       "o       10\n",
       "dd       4\n",
       "Name: x.6, dtype: int64"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data['x.6'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "53630982",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "f       139\n",
       "0.04    129\n",
       "1.5     119\n",
       "2.5     104\n",
       "5.0     101\n",
       "Name: x.7, dtype: int64"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data['x.7'].value_counts().head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "7f8ccf55",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "t    2257\n",
       "a     151\n",
       "c     147\n",
       "b     116\n",
       "Name: x.8, dtype: int64"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data['x.8'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "75585074",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "t    1662\n",
       "f    1009\n",
       "Name: x.9, dtype: int64"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data['x.9'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "4e5e64f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# data['x.10'].value_counts() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "2fc6b9b2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "f    1380\n",
       "t    1291\n",
       "Name: x.11, dtype: int64"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data['x.11'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "da194e9b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "g    2480\n",
       "s     157\n",
       "p      34\n",
       "Name: x.12, dtype: int64"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data['x.12'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "09bbf014",
   "metadata": {},
   "outputs": [],
   "source": [
    "# data['x.13'].value_counts()  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "c6a32e49",
   "metadata": {},
   "outputs": [],
   "source": [
    "# data['x.14'].value_counts() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "7bd1d97f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "f    1797\n",
       "?     668\n",
       "t     206\n",
       "Name: x.16, dtype: int64"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data['x.16'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "7e56922f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.25009359790340696"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## proportion of unknown values in 'x.16'\n",
    "668/2671"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "0016c418",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "142,71282893055113    21\n",
       "150,34527961856327    20\n",
       "76,48492583572703     20\n",
       "127,30605465811978    19\n",
       "74,2617471676903      18\n",
       "Name: x.17, dtype: int64"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data['x.17'].value_counts().head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "18d4f2cb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5,502009139465553     21\n",
       "35,66336266708667     20\n",
       "1,7196083330867018    20\n",
       "1,4567043474025236    19\n",
       "63,286150252172135    18\n",
       "Name: x.18, dtype: int64"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data['x.18'].value_counts().head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "78ca6604",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "f           658\n",
       "100000.0    157\n",
       "80000.0     146\n",
       "120000.0     92\n",
       "200000.0     86\n",
       "Name: x.19, dtype: int64"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data['x.19'].value_counts().head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "b6f15758",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "?    2180\n",
       "t     252\n",
       "f     239\n",
       "Name: x.20, dtype: int64"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data['x.20'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "2e8ef000",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8161737177087234"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## proportion of unknown values in 'x.20'\n",
    "2180/2671"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "1fb63982",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "good    2398\n",
       "bad      273\n",
       "Name: y, dtype: int64"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Check how balanced the dataset is using the target label\n",
    "data['y'].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "121aea81",
   "metadata": {},
   "source": [
    "**NOTE:**The Data understanding segment ensured I understood the data shape, data info and each feature in the dataset. Given the dataset is not very large, I was able to navigate through the data and discovered the following:\n",
    "\n",
    "- All the features are of data type object\n",
    "- Some features are majorly alphabets/letters with **\" ? \"** which I assumed to be unknown/missing data\n",
    "- Some features that are supposed to be of numerical data type has some alphabets/strings in them\n",
    "- some features have double letters in them e.g \" bb \", \" ff \" etc.\n",
    "- Some features have large missing information in them e.g. \" x.16 \" and \" x.20 \"\n",
    "- The dataset is not balanced\n",
    "\n",
    "\n",
    "All of the above concerns will be taken care of in the data cleaning/preprocessing section\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2a063f01",
   "metadata": {},
   "source": [
    "### Data Cleaning / Preprocessing\n",
    "\n",
    "The data cleaning/ preprocessing section is where we check for missing values and handle them appropriately, check for correct data format in each variable and convert to the appropriate format if not appropriate, remove white spaces in data if present, and generally make the data almost ready for further analysis."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3fc181b7",
   "metadata": {},
   "source": [
    "**Data Cleaning/Preprocessing Steps:**\n",
    "- Drop Variables/ Features with **\" ? \"** greater than 10% of the variable population. This is essential because variables with large missing values can cause bias in our model if handled poorly. \n",
    "- If a feature is supposed to be categorical or of data type object, replace **\" ? \"** with the modal class or replace with the next modal class if **\" ? \"** is the original modal class\n",
    "- In a supposed numerical variable replace **\" , \"** in numerical values with **\" . \"**. \n",
    "- A supposed numerical feature having string values like **\" f \"**, **\" b \"**  etc. These string values are being replaced with the median of the supposed numerical feature. This is done to ensure data homogeneity in the feature and reduce the effect of outliers when replacing them with median instead of mean.\n",
    "- In a supposed categorical feature, if an object appear in its double form. say **\" bb \"**, **\" tt \"**, it is strip down to return just a single value like **\" b \"** or **\" t \"**\n",
    "- A supposed numerical feature is being converted to float\n",
    "\n",
    "**NOTE:** Assumption made is that **\" ? \"** stands for an unknown value."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7c700ae8",
   "metadata": {},
   "source": [
    "#### Created some helper functions to help in data cleaning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "1e691d61",
   "metadata": {},
   "outputs": [],
   "source": [
    "def drop_large_missing_values(data):\n",
    "    '''\n",
    "    This function drops missing values or unknown values greater than 10%\n",
    "    of the variable population\n",
    "    \n",
    "    parameter::\n",
    "    - data :: Dataframe object\n",
    "    '''\n",
    "    # iteratively pick variables in the dataset\n",
    "    for var in data.columns:\n",
    "        # get count of each category in the variable and parse to dictionary\n",
    "        result = data[var].value_counts().to_dict()\n",
    "        # iteratively pick keys and values from parsed dictionary\n",
    "        for keys, values in result.items():\n",
    "            # if the condition holds and \" ? \" which is missing value greater than 10%\n",
    "            if keys == '?' and values/data[var].shape[0] > 0.10:\n",
    "                # drop the variable \n",
    "                data.drop(var, axis=1, inplace=True)\n",
    "            else:\n",
    "                pass\n",
    "    # return data         \n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "bed721cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# This function handles the preprocessing/ data cleaning steps outlined above\n",
    "def preprocess(data, variable):\n",
    "    '''\n",
    "    This function helps in cleaning the data \n",
    "    \n",
    "    parameters::\n",
    "    - data :: dataframe object\n",
    "    - variable :: variable to be cleaned\n",
    "    \n",
    "    output::\n",
    "    - returns a pandas series of the cleaned variable\n",
    "    '''\n",
    "    ## set empty list to track values in the variables\n",
    "    int_val = []\n",
    "    str_val = []\n",
    "    \n",
    "    # Iterate through the variable getting its unique value from a list\n",
    "    for i in data[variable].unique().tolist():\n",
    "        try:\n",
    "            # Here the variable is checked for commas. if present replace with '.', cast as float,\n",
    "            # and then append to int_val that tracks integer values\n",
    "            int_val.append(float(i.replace(',','.')))\n",
    "        except Exception as e:\n",
    "            # incase of exception, data casting to float was unsuccessful, then data is a string value\n",
    "            str_val.append(i)\n",
    "    \n",
    "    # get median value of numerica values in int val, this is used to replace letters or characters in \n",
    "    # a supposed numerical colum. Median was used in place of mean due to outlier's effect on mean value\n",
    "    median_val = np.median(int_val)\n",
    "    # For variables with dtype as object, get the modal class if not '?', '?' will be replaced with the modal class\n",
    "    mode_val = data[data[variable] != '?'][variable].mode().values[0]\n",
    "    \n",
    "    # if numerical value tracker is empty, then the current variable in consideration is most likely of object type\n",
    "    # Here we replace '?' with the next class with high frequency or mode.\n",
    "    if int_val == []:\n",
    "        data[variable] = np.where(data[variable] =='?', mode_val, data[variable])\n",
    "        # for double objects in variables like 'bb', 'ff' replace with just single occurence like 'b', 'f'\n",
    "        for j in data[variable].unique().tolist():\n",
    "            data[variable] = np.where(data[variable] == j , j[:1], data[variable])\n",
    "    else:\n",
    "        # Replace commas in numerical vales with period '.'\n",
    "        for index in data[variable].index:\n",
    "            data[variable][index] = data[variable][index].replace(',', '.')\n",
    "        # if there are characters in numerical columns, replace with the median value of the object in the column\n",
    "        data[variable] = np.where(data[variable].isin(str_val), median_val, data[variable])\n",
    "        # convert to float\n",
    "        data[variable] = data[variable].astype(np.float)\n",
    "        \n",
    "    # return a cleaned pandas series\n",
    "    return data[variable]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "45ba14c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "#################### Data Preprocessing #################################"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "5b67611c",
   "metadata": {},
   "outputs": [],
   "source": [
    "### Get a copy of the original data so as not to overwrite the original data and run our preprocessing steps\n",
    "training_data = data.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "cd6f5337",
   "metadata": {},
   "outputs": [],
   "source": [
    "### Encode Target Variable \n",
    "training_data['y'] = training_data['y'].replace({'good': '1', 'bad': '0'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "46fbba7e",
   "metadata": {},
   "outputs": [],
   "source": [
    "### Drop Variables with Large missing values ('?')\n",
    "training_data = drop_large_missing_values(training_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "b4fb97e3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2671, 19)"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## Dataset dimesnsion after dropping variables with large unknown values ('?')\n",
    "training_data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "6b436b2a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Apply data preprocessing function in order to clean the data\n",
    "for column in training_data.columns:\n",
    "    training_data[column] = preprocess(training_data, column)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "19994ad6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>x.0</th>\n",
       "      <th>x.1</th>\n",
       "      <th>x.2</th>\n",
       "      <th>x.3</th>\n",
       "      <th>x.4</th>\n",
       "      <th>x.5</th>\n",
       "      <th>x.6</th>\n",
       "      <th>x.7</th>\n",
       "      <th>x.8</th>\n",
       "      <th>x.9</th>\n",
       "      <th>x.10</th>\n",
       "      <th>x.11</th>\n",
       "      <th>x.12</th>\n",
       "      <th>x.13</th>\n",
       "      <th>x.14</th>\n",
       "      <th>x.17</th>\n",
       "      <th>x.18</th>\n",
       "      <th>x.19</th>\n",
       "      <th>y</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>b</td>\n",
       "      <td>30.83</td>\n",
       "      <td>5.3525</td>\n",
       "      <td>u</td>\n",
       "      <td>g</td>\n",
       "      <td>w</td>\n",
       "      <td>v</td>\n",
       "      <td>1.25</td>\n",
       "      <td>t</td>\n",
       "      <td>t</td>\n",
       "      <td>11.5</td>\n",
       "      <td>f</td>\n",
       "      <td>g</td>\n",
       "      <td>202.0</td>\n",
       "      <td>555.5</td>\n",
       "      <td>116.942570</td>\n",
       "      <td>0.578709</td>\n",
       "      <td>202000.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>a</td>\n",
       "      <td>58.67</td>\n",
       "      <td>4.4600</td>\n",
       "      <td>u</td>\n",
       "      <td>g</td>\n",
       "      <td>q</td>\n",
       "      <td>h</td>\n",
       "      <td>3.04</td>\n",
       "      <td>t</td>\n",
       "      <td>t</td>\n",
       "      <td>6.0</td>\n",
       "      <td>f</td>\n",
       "      <td>g</td>\n",
       "      <td>43.0</td>\n",
       "      <td>560.0</td>\n",
       "      <td>225.606253</td>\n",
       "      <td>25.409645</td>\n",
       "      <td>43000.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>a</td>\n",
       "      <td>24.50</td>\n",
       "      <td>0.5000</td>\n",
       "      <td>u</td>\n",
       "      <td>g</td>\n",
       "      <td>q</td>\n",
       "      <td>h</td>\n",
       "      <td>1.50</td>\n",
       "      <td>t</td>\n",
       "      <td>f</td>\n",
       "      <td>11.5</td>\n",
       "      <td>f</td>\n",
       "      <td>g</td>\n",
       "      <td>280.0</td>\n",
       "      <td>824.0</td>\n",
       "      <td>92.084077</td>\n",
       "      <td>2.317337</td>\n",
       "      <td>280000.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>b</td>\n",
       "      <td>27.83</td>\n",
       "      <td>1.5400</td>\n",
       "      <td>u</td>\n",
       "      <td>g</td>\n",
       "      <td>w</td>\n",
       "      <td>v</td>\n",
       "      <td>3.75</td>\n",
       "      <td>t</td>\n",
       "      <td>t</td>\n",
       "      <td>5.0</td>\n",
       "      <td>t</td>\n",
       "      <td>g</td>\n",
       "      <td>100.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>104.162918</td>\n",
       "      <td>8.045338</td>\n",
       "      <td>100000.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>b</td>\n",
       "      <td>20.17</td>\n",
       "      <td>5.6250</td>\n",
       "      <td>u</td>\n",
       "      <td>g</td>\n",
       "      <td>w</td>\n",
       "      <td>v</td>\n",
       "      <td>1.71</td>\n",
       "      <td>t</td>\n",
       "      <td>f</td>\n",
       "      <td>11.5</td>\n",
       "      <td>f</td>\n",
       "      <td>s</td>\n",
       "      <td>120.0</td>\n",
       "      <td>555.5</td>\n",
       "      <td>77.870302</td>\n",
       "      <td>31.111461</td>\n",
       "      <td>120000.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  x.0    x.1     x.2 x.3 x.4 x.5 x.6   x.7 x.8 x.9  x.10 x.11 x.12   x.13  \\\n",
       "0   b  30.83  5.3525   u   g   w   v  1.25   t   t  11.5    f    g  202.0   \n",
       "1   a  58.67  4.4600   u   g   q   h  3.04   t   t   6.0    f    g   43.0   \n",
       "2   a  24.50  0.5000   u   g   q   h  1.50   t   f  11.5    f    g  280.0   \n",
       "3   b  27.83  1.5400   u   g   w   v  3.75   t   t   5.0    t    g  100.0   \n",
       "4   b  20.17  5.6250   u   g   w   v  1.71   t   f  11.5    f    s  120.0   \n",
       "\n",
       "    x.14        x.17       x.18      x.19    y  \n",
       "0  555.5  116.942570   0.578709  202000.0  1.0  \n",
       "1  560.0  225.606253  25.409645   43000.0  1.0  \n",
       "2  824.0   92.084077   2.317337  280000.0  1.0  \n",
       "3    3.0  104.162918   8.045338  100000.0  1.0  \n",
       "4  555.5   77.870302  31.111461  120000.0  1.0  "
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## Sample of the data after being cleaned\n",
    "training_data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "70403163",
   "metadata": {},
   "source": [
    "**Note:** Variables \" x.16 \" and \" x.20 \" dropped due to high missing values in them"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "044c5301",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 2671 entries, 0 to 2670\n",
      "Data columns (total 19 columns):\n",
      " #   Column  Non-Null Count  Dtype  \n",
      "---  ------  --------------  -----  \n",
      " 0   x.0     2671 non-null   object \n",
      " 1   x.1     2671 non-null   float64\n",
      " 2   x.2     2671 non-null   float64\n",
      " 3   x.3     2671 non-null   object \n",
      " 4   x.4     2671 non-null   object \n",
      " 5   x.5     2671 non-null   object \n",
      " 6   x.6     2671 non-null   object \n",
      " 7   x.7     2671 non-null   float64\n",
      " 8   x.8     2671 non-null   object \n",
      " 9   x.9     2671 non-null   object \n",
      " 10  x.10    2671 non-null   float64\n",
      " 11  x.11    2671 non-null   object \n",
      " 12  x.12    2671 non-null   object \n",
      " 13  x.13    2671 non-null   float64\n",
      " 14  x.14    2671 non-null   float64\n",
      " 15  x.17    2671 non-null   float64\n",
      " 16  x.18    2671 non-null   float64\n",
      " 17  x.19    2671 non-null   float64\n",
      " 18  y       2671 non-null   float64\n",
      "dtypes: float64(10), object(9)\n",
      "memory usage: 481.9+ KB\n"
     ]
    }
   ],
   "source": [
    "## A quick info of the data after being cleaned returned in the right format\n",
    "training_data.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2efe8d34",
   "metadata": {},
   "source": [
    "#### Exploring through some of the variables after preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "48d4fe9c",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "b    1848\n",
       "a     823\n",
       "Name: x.0, dtype: int64"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "training_data['x.0'].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6f858e7b",
   "metadata": {},
   "source": [
    "**Note:** Feature \" x.0 \" had \" ? \" in the original data which has now been grouped into the \" b \" class which is the modal class in the feature"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "7a119951",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "23.25    47\n",
       "35.17    41\n",
       "39.92    37\n",
       "19.17    33\n",
       "20.42    28\n",
       "Name: x.1, dtype: int64"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## Variables with comma separation now have periods and converted to numerical \n",
    "training_data['x.1'].value_counts().head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "a13781dd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5.3525     125\n",
       "6.5000      74\n",
       "0.5000      70\n",
       "5.0000      69\n",
       "11.0000     66\n",
       "Name: x.2, dtype: int64"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# string within numberical variable has been replaced with the median value of the variable\n",
    "training_data['x.2'].value_counts().head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "1f6458f3",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "c    712\n",
       "q    564\n",
       "w    259\n",
       "x    198\n",
       "i    170\n",
       "a    159\n",
       "m    149\n",
       "k    145\n",
       "e    114\n",
       "f     85\n",
       "d     82\n",
       "j     25\n",
       "r      9\n",
       "Name: x.5, dtype: int64"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "training_data['x.5'].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7bb58f05",
   "metadata": {},
   "source": [
    "**Note:** Feature \"x.5\" had \" cc \", \" aa \" and \" ff \" in the original dataset. It has been cleaned to return c, a and f. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7d43f64e",
   "metadata": {},
   "source": [
    "After data cleaning, the dataset now have data in the right format necessary for further analysis. Also, the dataset now contains 10 variables with data type float64 and 9 with data type object"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "78e486be",
   "metadata": {},
   "source": [
    "### Data Preparation\n",
    "\n",
    "In this section, the data would be prepared for modelling and the following will be done:\n",
    "- **Feature Selection:** This is essential prior to modelling as not all independent variables has good information about the target variable in order to make them good predictors.\n",
    "- **Feature Engineering:** This is the creation of new variable from combination of one or more variable. This will be done if necessary\n",
    "- **Dummy variable creation/ Variable encoding:**  This is necessary as our machine learning algorithms only works best with numerical data. Here 1s and 0s represent the presence or abscence of a sample.\n",
    "- **Data Balancing:**   Since we are dealing with a very imbalance dataset, we will be employing the SMOTE technique to balance our dataset. This is essential to prevent the model biasing toward the majority class."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0894bf39",
   "metadata": {},
   "source": [
    "### Feature Selection\n",
    "\n",
    "Feature selection is a vital approach in data science because of variety of reasons, some of which will be listed here.\n",
    "\n",
    "- Helps in dimensionalty reduction which can in turn prevent overfitting and improve model performance\n",
    "- To provide faster models and also manage computation.\n",
    "- Better insight is gained as to how each feature contribute to the entire dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "33297584",
   "metadata": {},
   "source": [
    "#### Categorical Feature Selection\n",
    "\n",
    "The Chi-Squared test is used to determine the extent of relationship or dependence between two categorical variables â€” in this case, one categorical input feature, and the other, a categorical target variable. So we will iterativly run through the categorical features perfroming this test.\n",
    "\n",
    "In case of unencoded categorical features like we will be using here, a contingency table will be created using pandas crosstab which will help relate number of occurence of each category with the target variable after which Chi-squared test will then be carried out.\n",
    "\n",
    "A p-value will be returned along side other statiscal variables like degree of freedom etc. Since we care if the feature is relevant to predicting our target or not, a value lesser than 0.05 will assert that we reject the null hypothesis stating the feature is not relevant for predicting the target variable, in our case **\" y \" : Good or Bad**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "97bde281",
   "metadata": {},
   "outputs": [],
   "source": [
    "## This function selects categorical variables based on statistical significance to predicting the target variable\n",
    "def select_categorical_feats(data):\n",
    "    '''\n",
    "    This function estimates the statistical significance of categorical \n",
    "    variables with respect to predicting the target variable\n",
    "    \n",
    "    parameters ::\n",
    "    - data :: DataFrame Object\n",
    "    \n",
    "    output ::\n",
    "    - Dataframe result of variables in order of significance\n",
    "    '''\n",
    "    # define an empty dictionary to store chi-test results\n",
    "    chi2_check = {}\n",
    "    \n",
    "    # select only categorical variables\n",
    "    training_data_cat = data.select_dtypes(include = 'object')\n",
    "    \n",
    "    # iteratively pick columns and calculate chi statistic with the target variable\n",
    "    for column in training_data_cat.columns:\n",
    "        chi, p, dof, ex = chi2_contingency(pd.crosstab(data['y'], data[column]))\n",
    "        chi2_check.setdefault('Categorical_Features',[]).append(column)\n",
    "        chi2_check.setdefault('p-values',[]).append(round(p, 3))\n",
    "\n",
    "    # convert the dictionary to a DF\n",
    "    chi2_result = pd.DataFrame(data = chi2_check).sort_values('p-values', ascending=True, ignore_index=True)\n",
    "    \n",
    "    # return result\n",
    "    return chi2_result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "ce2a4c96",
   "metadata": {},
   "outputs": [],
   "source": [
    "### Using the select categorical feature function return statiscally significant categorical features\n",
    "stat_significant_cat_feats = select_categorical_feats(training_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "bbde3756",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Categorical_Features</th>\n",
       "      <th>p-values</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>x.3</td>\n",
       "      <td>0.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>x.4</td>\n",
       "      <td>0.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>x.5</td>\n",
       "      <td>0.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>x.6</td>\n",
       "      <td>0.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>x.8</td>\n",
       "      <td>0.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>x.9</td>\n",
       "      <td>0.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>x.12</td>\n",
       "      <td>0.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>x.11</td>\n",
       "      <td>0.026</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>x.0</td>\n",
       "      <td>0.292</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  Categorical_Features  p-values\n",
       "0                  x.3     0.000\n",
       "1                  x.4     0.000\n",
       "2                  x.5     0.000\n",
       "3                  x.6     0.000\n",
       "4                  x.8     0.000\n",
       "5                  x.9     0.000\n",
       "6                 x.12     0.000\n",
       "7                 x.11     0.026\n",
       "8                  x.0     0.292"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "stat_significant_cat_feats "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "e8d5801c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['x.3', 'x.4', 'x.5', 'x.6', 'x.8', 'x.9', 'x.12']"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Relevant categorical features in a list\n",
    "categorical_features = stat_significant_cat_feats.iloc[:7,0].to_list()\n",
    "categorical_features"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "29ad4492",
   "metadata": {},
   "source": [
    "#### Numerical Feature Selection\n",
    "\n",
    "The Analysis of Variance (ANOVA) F-statistic calculates the ratio of variances of the means of two or more samples of data. The higher this ratio between a numerical input feature and a categorical target feature, the lower the independence between the two and more likely to be useful for model training.\n",
    "\n",
    "Just as explained when using chi2 test for categorical feature selection. The f_classif returns some statistical variables along side a p-value for each feature. We select features with p-values lesser than 0.05 which inferes that the faeture is statiscally significant for the purpose of our prediction with respect to the target variable."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "a032e394",
   "metadata": {},
   "outputs": [],
   "source": [
    "## This function selects numerical variables based on statistical significance to predicting the target variable\n",
    "def select_numerical_feats(data):\n",
    "    '''\n",
    "    This function estimates the statistical significance of numerical \n",
    "    variables with respect to predicting the target variable\n",
    "    \n",
    "    parameters ::\n",
    "    - data :: DataFrame Object\n",
    "    \n",
    "    output ::\n",
    "    - Dataframe result of variables in order of significance\n",
    "    '''\n",
    "    # define an empty dictionary to store results\n",
    "    result = {}\n",
    "    \n",
    "    # select only numerical variables\n",
    "    training_data_num = data.select_dtypes(include = 'number')\n",
    "\n",
    "    for column in training_data_num.columns[:-1]:\n",
    "        # Calculate F Statistic and corresponding p values\n",
    "        F_statistic, p_values = f_classif(np.array(data[column]).reshape(-1,1), data['y'])\n",
    "        \n",
    "        # append relevant statistics to result dictionary\n",
    "        result.setdefault('Numerical_Features',[]).append(column)\n",
    "        result.setdefault('F-Scores',[]).append(round(F_statistic[0], 3))\n",
    "        result.setdefault('p-values',[]).append(round(p_values[0], 3))\n",
    " \n",
    "    # convert the dictionary to a DataFrame\n",
    "    result_df = pd.DataFrame(data = result).sort_values('p-values', ascending=True, ignore_index=True)\n",
    "    \n",
    "    # return result dataframe\n",
    "    return result_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "5b8705bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "### Using the select numerical feature function return statistically significant numerical features\n",
    "stat_significant_num_feats = select_numerical_feats(training_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "d6e67070",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Numerical_Features</th>\n",
       "      <th>F-Scores</th>\n",
       "      <th>p-values</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>x.1</td>\n",
       "      <td>40.877</td>\n",
       "      <td>0.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>x.2</td>\n",
       "      <td>45.926</td>\n",
       "      <td>0.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>x.7</td>\n",
       "      <td>62.837</td>\n",
       "      <td>0.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>x.14</td>\n",
       "      <td>14.637</td>\n",
       "      <td>0.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>x.17</td>\n",
       "      <td>43.829</td>\n",
       "      <td>0.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>x.18</td>\n",
       "      <td>43.922</td>\n",
       "      <td>0.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>x.10</td>\n",
       "      <td>2.315</td>\n",
       "      <td>0.128</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>x.13</td>\n",
       "      <td>0.557</td>\n",
       "      <td>0.455</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>x.19</td>\n",
       "      <td>0.557</td>\n",
       "      <td>0.455</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  Numerical_Features  F-Scores  p-values\n",
       "0                x.1    40.877     0.000\n",
       "1                x.2    45.926     0.000\n",
       "2                x.7    62.837     0.000\n",
       "3               x.14    14.637     0.000\n",
       "4               x.17    43.829     0.000\n",
       "5               x.18    43.922     0.000\n",
       "6               x.10     2.315     0.128\n",
       "7               x.13     0.557     0.455\n",
       "8               x.19     0.557     0.455"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "stat_significant_num_feats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "0e03a351",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['x.1', 'x.2', 'x.7', 'x.14', 'x.17', 'x.18']"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Relevant numerical features in a list\n",
    "num_features = stat_significant_num_feats.iloc[:6,0].to_list()\n",
    "num_features"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "327bf774",
   "metadata": {},
   "source": [
    "### Check Variable Correlation\n",
    "\n",
    "Another vital method in feature selection is checking how much each independent variable correlates with one another using spearman's correlation technique.\n",
    "\n",
    "Correlating variables tend to provide similar information about the target variable. Multi-Collinearity will prevent accurate prediction of the target variable as correlating features will predict each other more often than our variable of interst.\n",
    "\n",
    "To Prevent this from happening and also to have an optimized model, we check for correlation and drop one of the features having correlation greater than a specified threshold."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "f8ae4546",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>x.3</th>\n",
       "      <th>x.4</th>\n",
       "      <th>x.5</th>\n",
       "      <th>x.6</th>\n",
       "      <th>x.8</th>\n",
       "      <th>x.9</th>\n",
       "      <th>x.12</th>\n",
       "      <th>x.1</th>\n",
       "      <th>x.2</th>\n",
       "      <th>x.7</th>\n",
       "      <th>x.14</th>\n",
       "      <th>x.17</th>\n",
       "      <th>x.18</th>\n",
       "      <th>y</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>u</td>\n",
       "      <td>g</td>\n",
       "      <td>w</td>\n",
       "      <td>v</td>\n",
       "      <td>t</td>\n",
       "      <td>t</td>\n",
       "      <td>g</td>\n",
       "      <td>30.83</td>\n",
       "      <td>5.3525</td>\n",
       "      <td>1.25</td>\n",
       "      <td>555.5</td>\n",
       "      <td>116.942570</td>\n",
       "      <td>0.578709</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>u</td>\n",
       "      <td>g</td>\n",
       "      <td>q</td>\n",
       "      <td>h</td>\n",
       "      <td>t</td>\n",
       "      <td>t</td>\n",
       "      <td>g</td>\n",
       "      <td>58.67</td>\n",
       "      <td>4.4600</td>\n",
       "      <td>3.04</td>\n",
       "      <td>560.0</td>\n",
       "      <td>225.606253</td>\n",
       "      <td>25.409645</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>u</td>\n",
       "      <td>g</td>\n",
       "      <td>q</td>\n",
       "      <td>h</td>\n",
       "      <td>t</td>\n",
       "      <td>f</td>\n",
       "      <td>g</td>\n",
       "      <td>24.50</td>\n",
       "      <td>0.5000</td>\n",
       "      <td>1.50</td>\n",
       "      <td>824.0</td>\n",
       "      <td>92.084077</td>\n",
       "      <td>2.317337</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>u</td>\n",
       "      <td>g</td>\n",
       "      <td>w</td>\n",
       "      <td>v</td>\n",
       "      <td>t</td>\n",
       "      <td>t</td>\n",
       "      <td>g</td>\n",
       "      <td>27.83</td>\n",
       "      <td>1.5400</td>\n",
       "      <td>3.75</td>\n",
       "      <td>3.0</td>\n",
       "      <td>104.162918</td>\n",
       "      <td>8.045338</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>u</td>\n",
       "      <td>g</td>\n",
       "      <td>w</td>\n",
       "      <td>v</td>\n",
       "      <td>t</td>\n",
       "      <td>f</td>\n",
       "      <td>s</td>\n",
       "      <td>20.17</td>\n",
       "      <td>5.6250</td>\n",
       "      <td>1.71</td>\n",
       "      <td>555.5</td>\n",
       "      <td>77.870302</td>\n",
       "      <td>31.111461</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  x.3 x.4 x.5 x.6 x.8 x.9 x.12    x.1     x.2   x.7   x.14        x.17  \\\n",
       "0   u   g   w   v   t   t    g  30.83  5.3525  1.25  555.5  116.942570   \n",
       "1   u   g   q   h   t   t    g  58.67  4.4600  3.04  560.0  225.606253   \n",
       "2   u   g   q   h   t   f    g  24.50  0.5000  1.50  824.0   92.084077   \n",
       "3   u   g   w   v   t   t    g  27.83  1.5400  3.75    3.0  104.162918   \n",
       "4   u   g   w   v   t   f    s  20.17  5.6250  1.71  555.5   77.870302   \n",
       "\n",
       "        x.18    y  \n",
       "0   0.578709  1.0  \n",
       "1  25.409645  1.0  \n",
       "2   2.317337  1.0  \n",
       "3   8.045338  1.0  \n",
       "4  31.111461  1.0  "
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "selected_training_data = training_data[categorical_features + num_features + ['y']]\n",
    "selected_training_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "d0cc3166",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2671, 14)"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "selected_training_data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "3dadc552",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 864x864 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# calculate pair-wise correlations between the numerical features \n",
    "corrmat = selected_training_data.corr()\n",
    "\n",
    "plt.figure(figsize=(12,12))\n",
    "sns.heatmap(corrmat, annot=True);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "350f0fbb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check for correlation in the training dataset\n",
    "def get_correlated(data, threshold):\n",
    "    '''\n",
    "    This function returns variables with high correlation based on the threshold specified\n",
    "    '''\n",
    "    cols = set()\n",
    "    corrmat = data.corr()\n",
    "    for i in range(len(corrmat.columns)):\n",
    "        for j in range(i):\n",
    "            if corrmat.iloc[i,j] > threshold:\n",
    "                colname = corrmat.columns[i]\n",
    "                cols.add(colname)\n",
    "    return cols"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "b088c717",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'x.17', 'x.18'}"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# features having correlation greater than 0.9 will be dropped from our dataset\n",
    "correlating_variables = get_correlated(selected_training_data, 0.9)\n",
    "\n",
    "## These variables are correlating with other variables in the dataset\n",
    "correlating_variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "5d97eb1f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2671, 12)"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "### Drop correlating variables\n",
    "selected_training_data = selected_training_data.drop(list(correlating_variables), axis=1)\n",
    "selected_training_data.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6659f24f",
   "metadata": {},
   "source": [
    "### Encode Categorical Variables\n",
    "\n",
    "Because scikit learn algorithms won't accept strings, we have to encode our categorical features. **Since these features are nominal, we will apply an encoding that does not add rank to unique element of these features**, thus we will have 0s and 1s for when an observation is absent or present respectively. For this purpose, pandas get dummies will be used. To prevent the dummy variable trap, one of the encoded feature will be dropped."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "ebad6d08",
   "metadata": {},
   "outputs": [],
   "source": [
    "# function to create dummy variables\n",
    "def dummy_creation(data):\n",
    "    '''\n",
    "    This functions create dummy variables by selecting categorical varaibles from a dataframe\n",
    "    \n",
    "    parameters::\n",
    "    - data :: DataFrame Object\n",
    "    \n",
    "    output::\n",
    "    - DataFrame\n",
    "    '''\n",
    "    df_dummies = []\n",
    "    \n",
    "    # select only categorical variables\n",
    "    training_data_cat = data.select_dtypes(include = 'object')\n",
    "    # Iterate throught the columns\n",
    "    for column in training_data_cat.columns:\n",
    "        # using pandas get dummies, create a dummy variable across the selected variable dropping first dummy to \n",
    "        # prevent variable correlation\n",
    "        df_dummies.append(pd.get_dummies(data[column], prefix = column, drop_first=True, prefix_sep = '-'))\n",
    "    # Concatenate all dummy variables together   \n",
    "    df_dummies = pd.concat(df_dummies, axis = 1)\n",
    "    # Concatenate the newly created dummy variables with the old dataset\n",
    "    data = pd.concat([data, df_dummies], axis = 1)\n",
    "    # Drop original categorical variables from which dummy has been created\n",
    "    data.drop(training_data_cat.columns, axis=1,inplace = True)\n",
    "    \n",
    "    # Return dataset\n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "44b7294c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# create dummy variables for categorical features in the training dataset\n",
    "training_data = dummy_creation(selected_training_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "77813de0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>x.1</th>\n",
       "      <th>x.2</th>\n",
       "      <th>x.7</th>\n",
       "      <th>x.14</th>\n",
       "      <th>y</th>\n",
       "      <th>x.3-u</th>\n",
       "      <th>x.3-y</th>\n",
       "      <th>x.4-p</th>\n",
       "      <th>x.5-c</th>\n",
       "      <th>x.5-d</th>\n",
       "      <th>x.5-e</th>\n",
       "      <th>x.5-f</th>\n",
       "      <th>x.5-i</th>\n",
       "      <th>x.5-j</th>\n",
       "      <th>x.5-k</th>\n",
       "      <th>x.5-m</th>\n",
       "      <th>x.5-q</th>\n",
       "      <th>x.5-r</th>\n",
       "      <th>x.5-w</th>\n",
       "      <th>x.5-x</th>\n",
       "      <th>x.6-d</th>\n",
       "      <th>x.6-f</th>\n",
       "      <th>x.6-h</th>\n",
       "      <th>x.6-j</th>\n",
       "      <th>x.6-n</th>\n",
       "      <th>x.6-o</th>\n",
       "      <th>x.6-v</th>\n",
       "      <th>x.6-z</th>\n",
       "      <th>x.8-b</th>\n",
       "      <th>x.8-c</th>\n",
       "      <th>x.8-t</th>\n",
       "      <th>x.9-t</th>\n",
       "      <th>x.12-p</th>\n",
       "      <th>x.12-s</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>30.83</td>\n",
       "      <td>5.3525</td>\n",
       "      <td>1.25</td>\n",
       "      <td>555.5</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>58.67</td>\n",
       "      <td>4.4600</td>\n",
       "      <td>3.04</td>\n",
       "      <td>560.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>24.50</td>\n",
       "      <td>0.5000</td>\n",
       "      <td>1.50</td>\n",
       "      <td>824.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>27.83</td>\n",
       "      <td>1.5400</td>\n",
       "      <td>3.75</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>20.17</td>\n",
       "      <td>5.6250</td>\n",
       "      <td>1.71</td>\n",
       "      <td>555.5</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     x.1     x.2   x.7   x.14    y  x.3-u  x.3-y  x.4-p  x.5-c  x.5-d  x.5-e  \\\n",
       "0  30.83  5.3525  1.25  555.5  1.0      1      0      0      0      0      0   \n",
       "1  58.67  4.4600  3.04  560.0  1.0      1      0      0      0      0      0   \n",
       "2  24.50  0.5000  1.50  824.0  1.0      1      0      0      0      0      0   \n",
       "3  27.83  1.5400  3.75    3.0  1.0      1      0      0      0      0      0   \n",
       "4  20.17  5.6250  1.71  555.5  1.0      1      0      0      0      0      0   \n",
       "\n",
       "   x.5-f  x.5-i  x.5-j  x.5-k  x.5-m  x.5-q  x.5-r  x.5-w  x.5-x  x.6-d  \\\n",
       "0      0      0      0      0      0      0      0      1      0      0   \n",
       "1      0      0      0      0      0      1      0      0      0      0   \n",
       "2      0      0      0      0      0      1      0      0      0      0   \n",
       "3      0      0      0      0      0      0      0      1      0      0   \n",
       "4      0      0      0      0      0      0      0      1      0      0   \n",
       "\n",
       "   x.6-f  x.6-h  x.6-j  x.6-n  x.6-o  x.6-v  x.6-z  x.8-b  x.8-c  x.8-t  \\\n",
       "0      0      0      0      0      0      1      0      0      0      1   \n",
       "1      0      1      0      0      0      0      0      0      0      1   \n",
       "2      0      1      0      0      0      0      0      0      0      1   \n",
       "3      0      0      0      0      0      1      0      0      0      1   \n",
       "4      0      0      0      0      0      1      0      0      0      1   \n",
       "\n",
       "   x.9-t  x.12-p  x.12-s  \n",
       "0      1       0       0  \n",
       "1      1       0       0  \n",
       "2      0       0       0  \n",
       "3      1       0       0  \n",
       "4      0       0       1  "
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "training_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "5a6c5c5c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2671, 34)"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "training_data.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c3cc506b",
   "metadata": {},
   "source": [
    "### Apply All Data Cleaning and Data Preparation Steps on Validation Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "f5f631a1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(490, 21)"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Read in validation dataset\n",
    "val_data = pd.read_csv('validation_grover.csv',sep=';', index_col=0)\n",
    "val_data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "fac36afb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "bad     336\n",
       "good    154\n",
       "Name: y, dtype: int64"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "val_data['y'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "3fbcf2fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "### Apply steps\n",
    "\n",
    "# 1. Drop variables with Large Missing/Unknown Values ['x.16' and 'x.20'] just like in training data\n",
    "val_data = val_data.drop(['x.16','x.20'], axis=1)\n",
    "\n",
    "# 2. Encode Target Variable \n",
    "val_data['y'] = val_data['y'].replace({'good': '1', 'bad': '0'})\n",
    "\n",
    "# 3. Clean Data\n",
    "for column in val_data.columns:\n",
    "    val_data[column] = preprocess(val_data, column)\n",
    "\n",
    "# 4. Select significant variables\n",
    "val_data = val_data[categorical_features + num_features + ['y']]\n",
    "\n",
    "# 5. Drop Correlating variables\n",
    "val_data = val_data.drop(list(correlating_variables), axis=1)\n",
    "\n",
    "# 6. Dummy variables creation\n",
    "val_data = dummy_creation(val_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "f0a874fa",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(490, 34)"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# validation Data Dimension after cleaning and preparation\n",
    "val_data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "61b226e6",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "0deaec7f",
   "metadata": {},
   "source": [
    "### Data Splitting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "4d09b2aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split training dataset\n",
    "X_train = training_data.drop('y', axis=1)\n",
    "y_train = training_data['y']\n",
    "\n",
    "# Split validation dataset\n",
    "X_val = val_data.drop('y', axis=1)\n",
    "y_val = val_data['y']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f26c3a40",
   "metadata": {},
   "source": [
    "### Balance Training Dataset\n",
    "\n",
    "A balanced dataset is vital when building predictive models. Imbalanced dataset will result in a model predicting the majority class most of the time. The result of this being that it understands the trend of the majority class better than the minority class(es).\n",
    "\n",
    "There are different methods of balancing datasets in other to get the best of our trained model. The most common methods are:\n",
    "\n",
    "1. Undersampling\n",
    "2. Oversampling\n",
    "3. Synthetic minority over-sampling technique (SMOTE)\n",
    "\n",
    "Undersampling simply reduces the observation in the majority class(es) balancing it with class with the least observation. Undersampling is not very efficient as information will be lost when obsevations are being dropped from the majority class(es). Oversampling does the opposite but with a little difference when considering SMOTE.\n",
    "\n",
    "For this task, we will be using SMOTE as it has proven to be the best method of generating samples to balance up the minority class(es). SMOTE simply synthesizes elements of the minority class using the existing ones. It randomly chooses a point from the minority class and computes the k-nearest neighbors (default = 5) for this point. The synthetic points are added between the chosen point and its neighbors by choosing a factor between 0 and 1 to multiply the distance.\n",
    "\n",
    "**NOTE:** Data balancing is done only on the training data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "763ded1e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Using SMOTE from imbalance learn (imblearn)\n",
    "smote = SMOTE(sampling_strategy='auto', random_state=42)\n",
    "X_train, y_train = smote.fit_resample(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "9d09676f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Counter({1.0: 2398, 0.0: 2398})"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Check to see if the dataset is now balanced \n",
    "from collections import Counter\n",
    "Counter(y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bf0a1efb",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "e4182dab",
   "metadata": {},
   "source": [
    "### Modelling and Evaluation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d902e47d",
   "metadata": {},
   "source": [
    "Now that we have a cleaned, well prepared and balanced training dataset. It is time to train our model. While bunch of machine learning tasks is done during data preprocessing and preparation, modelling also require special skills in order to build a robust model.\n",
    "\n",
    "In this modellind section, I will be doing the following:\n",
    "\n",
    "- Create a pipeline which holds all the processes involved in training the model\n",
    "- Train at least 5 or 6 machine learning algorithms and select the best using Cross Validation Technique\n",
    "- We fit the data on the best algorithm \n",
    "- Hyperparametere Tune the selected algorithm if necessary\n",
    "- Evaluate the newly built model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "96713647",
   "metadata": {},
   "source": [
    "#### Cross Validation for algorithm selection\n",
    "\n",
    "Cross-validation is a technique majorly used for preventing overfitting. However, it has been used over time in algorithm selection. Cross-validation works by splitting the entire dataset into K number of folds as specified.\n",
    "\n",
    "For every iteration given a K value, the dataset is splitted into training dataset and validation dataset based on the K value at that iteration. The advantage of using cross-validation during training and algortihm selection is that it uses the entire dataset in the process, there by validating on a specified split and train on the rest of the dataset.\n",
    "\n",
    "Running cross-validation of different algorithm returns a mean accuracy score which shows which algorithm fits well with the data.\n",
    "\n",
    "A further step can be to do hyper-parameter tuning on the algorithms with the best mean accuracy to better optimize them for modelling."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "03ffb42d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# This function performs cross-validation on algorithms and return its mean accuracy\n",
    "def select_algo(algo, X, y):\n",
    "    '''\n",
    "    This function runs cross validation on data and returns mean accuracy\n",
    "    \n",
    "    prarmeters ::\n",
    "    - algo :: Machine Learning Algorithm\n",
    "    - X :: Independent variables\n",
    "    - y :: Target Variable\n",
    "    '''\n",
    "    cv_scores=cross_val_score(algo, X, y, cv=10, scoring='accuracy')\n",
    "    \n",
    "    return cv_scores.mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "2e269cb9",
   "metadata": {},
   "outputs": [],
   "source": [
    "## The 6 selected algorithms(classifiers) to test\n",
    "classifiers = []\n",
    "\n",
    "classifiers.append(('Logistic Regression', LogisticRegression()))\n",
    "classifiers.append(('Ada Boost Classifier', AdaBoostClassifier()))\n",
    "classifiers.append(('KNN', KNeighborsClassifier()))\n",
    "classifiers.append(('Decision Tree', DecisionTreeClassifier()))\n",
    "classifiers.append(('Random Forest', RandomForestClassifier()))\n",
    "classifiers.append(('Naive Bayes', GaussianNB()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "d7da6db1",
   "metadata": {},
   "outputs": [],
   "source": [
    "#### This process would iteratively pick the above stated algorithms, create a machine learning pipeline and fit the data\n",
    "best_algo = {}\n",
    "\n",
    "for classifier in classifiers:\n",
    "    \n",
    "    ### Pipeline creation\n",
    "    pipeline = Pipeline([('Standard Scaler', StandardScaler())])\n",
    "    pipeline.steps.append(classifier)\n",
    "    \n",
    "    ## The select_algo function is instantiated here, this would return a mean score from the cross-validation process\n",
    "    cv_score = select_algo(pipeline, X_train, y_train)\n",
    "    \n",
    "    best_algo.setdefault('Classifier',[]).append(classifier[0])\n",
    "    best_algo.setdefault('cv_score',[]).append(cv_score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "aa470391",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Classifier</th>\n",
       "      <th>cv_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Random Forest</td>\n",
       "      <td>0.993125</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Decision Tree</td>\n",
       "      <td>0.986874</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>KNN</td>\n",
       "      <td>0.979790</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Ada Boost Classifier</td>\n",
       "      <td>0.954357</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Logistic Regression</td>\n",
       "      <td>0.938303</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Naive Bayes</td>\n",
       "      <td>0.902025</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             Classifier  cv_score\n",
       "0         Random Forest  0.993125\n",
       "1         Decision Tree  0.986874\n",
       "2                   KNN  0.979790\n",
       "3  Ada Boost Classifier  0.954357\n",
       "4   Logistic Regression  0.938303\n",
       "5           Naive Bayes  0.902025"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "### The Result of the Cross Validatio process highlighting how the algorithms fit the data\n",
    "pd.DataFrame(best_algo).sort_values('cv_score', ascending=False, ignore_index=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "80cbf403",
   "metadata": {},
   "source": [
    "The Above process shows the *best algorithm* to fit the data with is the **Random Forest Classifier**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "def830c7",
   "metadata": {},
   "source": [
    "### Hyper Parameter Tuning\n",
    "\n",
    "The Major purpose of tuning parameters of an algorithm is to optimally get the best performance of the algorithm. We select few parameters to tune leaving the rest as default and then run iterations which is the number of times the training will occur randomly picking the parameters against themselves.\n",
    "\n",
    "Tuning parameter can be done using **GridSearch** or **RandomizedSearch**. \n",
    "\n",
    "**RandomizedSearch is used here due to the fact that GridSearch can be computationally expensive**.\n",
    "\n",
    "While they give approximately the same result. GridSearch does more but takes time to fit the data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "493a25ef",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 2 folds for each of 10 candidates, totalling 20 fits\n",
      "Fitting 3 folds for each of 10 candidates, totalling 30 fits\n",
      "Fitting 4 folds for each of 10 candidates, totalling 40 fits\n",
      "Fitting 5 folds for each of 10 candidates, totalling 50 fits\n",
      "Fitting 6 folds for each of 10 candidates, totalling 60 fits\n",
      "Fitting 7 folds for each of 10 candidates, totalling 70 fits\n",
      "Fitting 8 folds for each of 10 candidates, totalling 80 fits\n",
      "Fitting 9 folds for each of 10 candidates, totalling 90 fits\n",
      "Fitting 10 folds for each of 10 candidates, totalling 100 fits\n",
      "Fitting 11 folds for each of 10 candidates, totalling 110 fits\n"
     ]
    }
   ],
   "source": [
    "### Instantiate the classifier\n",
    "rfc = RandomForestClassifier()\n",
    "\n",
    "# Scale training data to be used to prevent bias\n",
    "scaler = StandardScaler()\n",
    "X_train_tune = scaler.fit_transform(X_train)\n",
    "\n",
    "# Randomly select parameters to tune\n",
    "param_dist = dict(\n",
    "    n_estimators = [100,200,300,400,500], \n",
    "    criterion=[\"gini\", \"entropy\"],\n",
    "    random_state=[5,10,15,20,25],\n",
    "    class_weight = [\"balanced\", \"balanced_subsample\"],\n",
    ")\n",
    "\n",
    "## Range of cross-validation during tuninig\n",
    "k_range = range(2, 12)\n",
    "\n",
    "# An empty dictionary to tack tuning results \n",
    "k_score = {}\n",
    "\n",
    "for k in k_range:\n",
    "    rfc_random = RandomizedSearchCV(rfc, param_dist, cv=k, scoring='accuracy',n_iter=10, n_jobs=-1,verbose=1)\n",
    "    rfc_random.fit(X_train_tune, y_train)\n",
    "\n",
    "    k_score.setdefault('Best Accuracy',[]).append(rfc_random.best_score_)\n",
    "    k_score.setdefault('Best tuned parameter',[]).append(rfc_random.best_params_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "733b28b9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Best Accuracy</th>\n",
       "      <th>Best tuned parameter</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.991034</td>\n",
       "      <td>{'random_state': 15, 'n_estimators': 100, 'cri...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.990828</td>\n",
       "      <td>{'random_state': 20, 'n_estimators': 300, 'cri...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.992077</td>\n",
       "      <td>{'random_state': 5, 'n_estimators': 300, 'crit...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.992500</td>\n",
       "      <td>{'random_state': 25, 'n_estimators': 200, 'cri...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.992083</td>\n",
       "      <td>{'random_state': 10, 'n_estimators': 500, 'cri...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0.992295</td>\n",
       "      <td>{'random_state': 25, 'n_estimators': 400, 'cri...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0.992083</td>\n",
       "      <td>{'random_state': 15, 'n_estimators': 100, 'cri...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0.992495</td>\n",
       "      <td>{'random_state': 10, 'n_estimators': 400, 'cri...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>0.993125</td>\n",
       "      <td>{'random_state': 25, 'n_estimators': 100, 'cri...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>0.993536</td>\n",
       "      <td>{'random_state': 10, 'n_estimators': 100, 'cri...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Best Accuracy                               Best tuned parameter\n",
       "0       0.991034  {'random_state': 15, 'n_estimators': 100, 'cri...\n",
       "1       0.990828  {'random_state': 20, 'n_estimators': 300, 'cri...\n",
       "2       0.992077  {'random_state': 5, 'n_estimators': 300, 'crit...\n",
       "3       0.992500  {'random_state': 25, 'n_estimators': 200, 'cri...\n",
       "4       0.992083  {'random_state': 10, 'n_estimators': 500, 'cri...\n",
       "5       0.992295  {'random_state': 25, 'n_estimators': 400, 'cri...\n",
       "6       0.992083  {'random_state': 15, 'n_estimators': 100, 'cri...\n",
       "7       0.992495  {'random_state': 10, 'n_estimators': 400, 'cri...\n",
       "8       0.993125  {'random_state': 25, 'n_estimators': 100, 'cri...\n",
       "9       0.993536  {'random_state': 10, 'n_estimators': 100, 'cri..."
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "### Result of Hyperparameter Tuning by Number of CV\n",
    "hyp_result = pd.DataFrame(k_score)\n",
    "hyp_result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "369fcc13",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'random_state': 10,\n",
       " 'n_estimators': 100,\n",
       " 'criterion': 'gini',\n",
       " 'class_weight': 'balanced'}"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## Get the best parameters returned for Result with the Highes Accuracy\n",
    "best_parameters = hyp_result[hyp_result['Best Accuracy']==hyp_result['Best Accuracy'].max()]['Best tuned parameter'].values[0]\n",
    "best_parameters"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5a7a4af2",
   "metadata": {},
   "source": [
    "### Fit Random Forest Classifier with the best parameters\n",
    "\n",
    "**Scaling and Normalization**\n",
    "\n",
    "Scaling and Normalization is an essential part of every ML process. The reason for this is to prevent bias in our model training process. Scikit learn algorithms tend to attach more importance to features with large numerical figures making the model bias towards features with large numerics. To prevent this and ensure our algorithm train without bias, we scale the dataset. There are differnt methods of scaling our dataset, StandardScaler, MinMax scaler etc.\n",
    "\n",
    "For this task, StandardScaler is used and as a result, we infuse it in the ML pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "788c3016",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Instantiate the ML pipeline and fit using the best possible parameters\n",
    "rfc_classifier = Pipeline([\n",
    "    ('Standard Scaler', StandardScaler()),\n",
    "    ('Random Forest', RandomForestClassifier(**best_parameters))\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "501ef824",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Pipeline(steps=[('Standard Scaler', StandardScaler()),\n",
       "                ('Random Forest',\n",
       "                 RandomForestClassifier(class_weight='balanced',\n",
       "                                        random_state=10))])"
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "### Train the model\n",
    "rfc_classifier.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "67b95bbd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make prediction on validation data\n",
    "predictions = rfc_classifier.predict(X_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "5d47b533",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.95      0.95      0.95       336\n",
      "         1.0       0.90      0.90      0.90       154\n",
      "\n",
      "    accuracy                           0.93       490\n",
      "   macro avg       0.92      0.92      0.92       490\n",
      "weighted avg       0.93      0.93      0.93       490\n",
      "\n"
     ]
    }
   ],
   "source": [
    "## Classification Report \n",
    "print(classification_report(y_val, predictions))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "9157cdba",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Confusion Matrix\n",
    "cm = confusion_matrix(y_val, predictions)\n",
    "\n",
    "ax= plt.subplot()\n",
    "sns.heatmap(cm, annot=True, fmt='g', ax=ax, cbar=False)\n",
    "\n",
    "# # labels, title and ticks\n",
    "ax.set_xlabel('\\n Predicted')\n",
    "ax.set_ylabel('Actual \\n')\n",
    "ax.set_title('Confusion Matrix \\n')\n",
    "ax.xaxis.set_ticklabels(['Bad', 'Good'])\n",
    "ax.yaxis.set_ticklabels(['Bad', 'Good']);"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fd8beec7",
   "metadata": {},
   "source": [
    "#### Model Evaluation Report"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "66c67254",
   "metadata": {},
   "source": [
    "The classification report shows some of the best metrics to evaluating machine learning classification tasks (Binary Classifications or Multi-class classifications). It gives extended report in terms of the model precision, recall, fi-score and a general accuracy report.\n",
    "\n",
    "From our classification report it is observed the trained model has a general accuracy of **93% on the validation data**, and it performs well when predicting bad samples as evident in the f1-score of 0.95 to 0.90 for good samples. This is due to the proportion of good samples in the validation dataset. While it is not imperative for all the target class to be equal in proportion, it expected they are fairly close to have a robust data.\n",
    "\n",
    "F1-score is the preffered metric used here as it combines precision and recall in its computation and as such provides the best estimate when prediciting class or category of any classification problem rather than just using accuracy.\n",
    "\n",
    "In the confusion matrix, out of 336 Bad observations, the model was able to predict 320 correctly and out of 154 Good observations, it was able to predict 138 correctly. The model is performing well but can be improved on."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4d4bd64f",
   "metadata": {},
   "source": [
    "### Conclusion\n",
    "\n",
    "Given the model has a 99% accuracy on training data and 93% on validation data shows it is performing well enough and has not overfitted by prediciting unseen data fairly well. \n",
    "\n",
    "The model can be further improved on if more bad samples or observation can be obtained in the training data. This would ensure a much more robust model built on real data instead of relying on SMOTE to balance the data using a synthesized data."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "81da78ab",
   "metadata": {},
   "source": [
    "# ! $\\;\\;\\;\\;\\;\\;\\;\\;\\;\\;\\;\\;\\;\\;\\;\\;\\;\\;\\;\\;\\;\\;$  I HAD FUN WORKING ON THIS! ðŸ™‚"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ab99552c",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
